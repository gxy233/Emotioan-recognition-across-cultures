{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from LMlstm import SIFT_LSTM\n",
    "from loadLabels import load_labels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from loadfeat import load_FeatfromCSV,split_train_val\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_input_data(dataset,labels):\n",
    "\n",
    "    input_data=[]\n",
    "    input_labels=[]\n",
    "    for foldername in list(dataset.keys()):\n",
    "        \n",
    "        data=dataset[foldername]\n",
    "        label=labels[foldername]\n",
    "        \n",
    "        tensordata=torch.tensor(data)\n",
    "        tensorlabel=torch.tensor(label)\n",
    "\n",
    "        input_data.append(tensordata)\n",
    "        input_labels.append(tensorlabel)\n",
    "\n",
    "    return input_data,input_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(csv_files)=102\n",
      "finish loading dataset\n"
     ]
    }
   ],
   "source": [
    "AU_dir = '/home/ubuntu/gxy/535proj/FacialLMextraction/extractedLM/AUs'\n",
    "labels_dir = \"/home/ubuntu/gxy/535proj/dataset/SEWAv02\"\n",
    "lang='C1'\n",
    "dataset=load_FeatfromCSV(AU_dir,lang)\n",
    "print('finish loading dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish split_train_val dataset\n",
      "Training set length: 81\n",
      "Length of the first element in train_data: 801\n",
      "Validation set length: 21\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = split_train_val(dataset)\n",
    "print('finish split_train_val dataset')\n",
    "    # Output the lengths of training and validation sets\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(f'Length of the first element in train_data: {len(list(train_data.values())[0])}')\n",
    "print(\"Validation set length:\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(files)=102\n",
      "processing SSL_C1_S194_P388_VC1_005501_005901_Arousal_AV_Aligned\n",
      "processing SAH_C1_S029_P058_VC1_006573_007472_Arousal_AV_Aligned\n",
      "processing SAL_C1_S001_P002_VC1_000921_001732_Arousal_AV_Aligned\n",
      "processing SSD_C1_S023_P045_VC1_001801_002201_Arousal_AV_Aligned\n",
      "processing SAH_C1_S009_P018_VC1_004321_005367_Arousal_AV_Aligned\n",
      "processing SVL_C1_S006_P012_VC1_007601_008701_Arousal_AV_Aligned\n",
      "processing SSD_C1_S026_P052_VC1_001101_001901_Arousal_AV_Aligned\n",
      "processing SSD_C1_S022_P044_VC1_007401_008001_Arousal_AV_Aligned\n",
      "processing SVH_C1_S027_P054_VC1_001601_002101_Arousal_AV_Aligned\n",
      "processing SVL_C1_S192_P384_VC1_003696_005031_Arousal_AV_Aligned\n",
      "processing SAH_C1_S028_P055_VC1_003774_004919_Arousal_AV_Aligned\n",
      "processing SVH_C1_S028_P055_VC1_000001_000801_Arousal_AV_Aligned\n",
      "processing SSL_C1_S018_P035_VC1_002201_002701_Arousal_AV_Aligned\n",
      "processing SSD_C1_S023_P046_VC1_003001_003501_Arousal_AV_Aligned\n",
      "processing SVL_C1_S014_P027_VC1_004045_006075_Arousal_AV_Aligned\n",
      "processing SAH_C1_S028_P056_VC1_001001_001771_Arousal_AV_Aligned\n",
      "processing SAH_C1_S027_P054_VC1_000920_002082_Arousal_AV_Aligned\n",
      "processing SVH_C1_S017_P033_VC1_004001_004801_Arousal_AV_Aligned\n",
      "processing SVL_C1_S022_P044_VC1_007329_008693_Arousal_AV_Aligned\n",
      "processing SVH_C1_S192_P384_VC1_006801_007351_Arousal_AV_Aligned\n",
      "processing SVH_C1_S006_P011_VC1_006001_006601_Arousal_AV_Aligned\n",
      "processing SAH_C1_S194_P388_VC1_003531_004419_Arousal_AV_Aligned\n",
      "processing SAL_C1_S021_P041_VC1_004951_006354_Arousal_AV_Aligned\n",
      "processing SAL_C1_S007_P013_VC1_001301_002076_Arousal_AV_Aligned\n",
      "processing SAL_C1_S003_P006_VC1_001561_002366_Arousal_AV_Aligned\n",
      "processing SVL_C1_S008_P015_VC1_002201_003201_Arousal_AV_Aligned\n",
      "processing SVH_C1_S009_P017_VC1_008201_008765_Arousal_AV_Aligned\n",
      "processing SVL_C1_S027_P053_VC1_002061_003937_Arousal_AV_Aligned\n",
      "processing SSD_C1_S012_P023_VC1_002701_003301_Arousal_AV_Aligned\n",
      "processing SVH_C1_S192_P383_VC1_004501_004701_Arousal_AV_Aligned\n",
      "processing SAH_C1_S029_P057_VC1_003201_004052_Arousal_AV_Aligned\n",
      "processing SAL_C1_S019_P038_VC1_005801_008601_Arousal_AV_Aligned\n",
      "processing SSL_C1_S001_P001_VC1_008151_008771_Arousal_AV_Aligned\n",
      "processing SAH_C1_S024_P048_VC1_000845_002039_Arousal_AV_Aligned\n",
      "processing SSD_C1_S027_P053_VC1_002401_003901_Arousal_AV_Aligned\n",
      "processing SAH_C1_S013_P025_VC1_006901_008783_Arousal_AV_Aligned\n",
      "processing SVH_C1_S008_P015_VC1_000001_000801_Arousal_AV_Aligned\n",
      "processing SSD_C1_S193_P385_VC1_004901_006301_Arousal_AV_Aligned\n",
      "processing SAL_C1_S011_P022_VC1_006951_008001_Arousal_AV_Aligned\n",
      "processing SSD_C1_S014_P027_VC1_004401_005801_Arousal_AV_Aligned\n",
      "processing SVL_C1_S014_P028_VC1_002595_004043_Arousal_AV_Aligned\n",
      "processing SSD_C1_S018_P036_VC1_002801_003601_Arousal_AV_Aligned\n",
      "processing SVL_C1_S018_P036_VC1_002718_004073_Arousal_AV_Aligned\n",
      "processing SSL_C1_S009_P018_VC1_004301_005301_Arousal_AV_Aligned\n",
      "processing SSL_C1_S018_P035_VC1_004301_004601_Arousal_AV_Aligned\n",
      "processing SAH_C1_S022_P044_VC1_007329_008693_Arousal_AV_Aligned\n",
      "processing SSD_C1_S022_P044_VC1_003301_004101_Arousal_AV_Aligned\n",
      "processing SSL_C1_S005_P010_VC1_000001_001401_Arousal_AV_Aligned\n",
      "processing SSD_C1_S004_P007_VC1_001001_001901_Arousal_AV_Aligned\n",
      "processing SVL_C1_S026_P052_VC1_001097_002123_Arousal_AV_Aligned\n",
      "processing SSL_C1_S194_P387_VC1_004401_005501_Arousal_AV_Aligned\n",
      "processing SSL_C1_S029_P057_VC1_003151_003901_Arousal_AV_Aligned\n",
      "processing SVH_C1_S022_P043_VC1_002401_003501_Arousal_AV_Aligned\n",
      "processing SSL_C1_S014_P028_VC1_000601_001201_Arousal_AV_Aligned\n",
      "processing SAH_C1_S005_P010_VC1_000001_000801_Arousal_AV_Aligned\n",
      "processing SVH_C1_S017_P033_VC1_007001_007601_Arousal_AV_Aligned\n",
      "processing SVL_C1_S017_P034_VC1_001001_003801_Arousal_AV_Aligned\n",
      "processing SSL_C1_S194_P387_VC1_002301_003501_Arousal_AV_Aligned\n",
      "processing SVH_C1_S194_P388_VC1_005201_005901_Arousal_AV_Aligned\n",
      "processing SAL_C1_S025_P050_VC1_000701_001916_Arousal_AV_Aligned\n",
      "processing SVL_C1_S022_P044_VC1_003301_004095_Arousal_AV_Aligned\n",
      "processing SSL_C1_S030_P060_VC1_002301_002701_Arousal_AV_Aligned\n",
      "processing SSL_C1_S022_P043_VC1_004901_005301_Arousal_AV_Aligned\n",
      "processing SAH_C1_S008_P016_VC1_005601_006984_Arousal_AV_Aligned\n",
      "processing SAL_C1_S010_P020_VC1_002611_003701_Arousal_AV_Aligned\n",
      "processing SSD_C1_S029_P058_VC1_000601_001201_Arousal_AV_Aligned\n",
      "processing SSD_C1_S006_P012_VC1_002101_002801_Arousal_AV_Aligned\n",
      "processing SSD_C1_S025_P050_VC1_004701_005301_Arousal_AV_Aligned\n",
      "processing SSD_C1_S001_P002_VC1_002001_002701_Arousal_AV_Aligned\n",
      "processing SSL_C1_S008_P015_VC1_003401_004201_Arousal_AV_Aligned\n",
      "processing SAL_C1_S029_P057_VC1_005264_006249_Arousal_AV_Aligned\n",
      "processing SAH_C1_S018_P036_VC1_001394_002328_Arousal_AV_Aligned\n",
      "processing SAH_C1_S009_P017_VC1_004001_006201_Arousal_AV_Aligned\n",
      "processing SVL_C1_S023_P046_VC1_003001_004187_Arousal_AV_Aligned\n",
      "processing SAL_C1_S007_P014_VC1_002076_003143_Arousal_AV_Aligned\n",
      "processing SAL_C1_S016_P031_VC1_004201_005001_Arousal_AV_Aligned\n",
      "processing SAL_C1_S016_P031_VC1_001801_003001_Arousal_AV_Aligned\n",
      "processing SSD_C1_S014_P027_VC1_003101_004001_Arousal_AV_Aligned\n",
      "processing SSL_C1_S024_P048_VC1_005801_006801_Arousal_AV_Aligned\n",
      "processing SAL_C1_S024_P047_VC1_002039_003624_Arousal_AV_Aligned\n",
      "processing SAH_C1_S027_P053_VC1_006932_008715_Arousal_AV_Aligned\n",
      "processing SVL_C1_S001_P001_VC1_003857_004977_Arousal_AV_Aligned\n",
      "processing SVH_C1_S013_P025_VC1_002001_003001_Arousal_AV_Aligned\n",
      "processing SSL_C1_S020_P039_VC1_006701_007701_Arousal_AV_Aligned\n",
      "processing SSD_C1_S025_P049_VC1_004201_004601_Arousal_AV_Aligned\n",
      "processing SVL_C1_S021_P041_VC1_002541_003447_Arousal_AV_Aligned\n",
      "processing SVH_C1_S194_P387_VC1_003501_003901_Arousal_AV_Aligned\n",
      "processing SAL_C1_S012_P024_VC1_006001_008775_Arousal_AV_Aligned\n",
      "processing SAH_C1_S013_P025_VC1_000997_002939_Arousal_AV_Aligned\n",
      "processing SVL_C1_S028_P056_VC1_007073_008192_Arousal_AV_Aligned\n",
      "processing SSD_C1_S023_P045_VC1_003701_004001_Arousal_AV_Aligned\n",
      "processing SAL_C1_S002_P004_VC1_002601_003428_Arousal_AV_Aligned\n",
      "processing SAL_C1_S017_P034_VC1_001001_003801_Arousal_AV_Aligned\n",
      "processing SSD_C1_S001_P001_VC1_004201_005201_Arousal_AV_Aligned\n",
      "processing SAH_C1_S001_P001_VC1_003857_004977_Arousal_AV_Aligned\n",
      "processing SVH_C1_S027_P053_VC1_000001_000801_Arousal_AV_Aligned\n",
      "processing SAL_C1_S031_P062_VC1_001438_002301_Arousal_AV_Aligned\n",
      "processing SAH_C1_S014_P028_VC1_000588_001854_Arousal_AV_Aligned\n",
      "processing SAH_C1_S192_P384_VC1_006367_008663_Arousal_AV_Aligned\n",
      "processing SSL_C1_S013_P025_VC1_001001_001601_Arousal_AV_Aligned\n",
      "processing SVH_C1_S027_P053_VC1_001601_002101_Arousal_AV_Aligned\n",
      "processing SSL_C1_S022_P044_VC1_000901_002201_Arousal_AV_Aligned\n",
      "finish loading labels\n",
      "finish load_training_data\n",
      "finish load_val_data\n"
     ]
    }
   ],
   "source": [
    "labels=load_labels(root_dir=labels_dir,language='C1',type='Arousal',suffix='AV_Aligned')\n",
    "print('finish loading labels')\n",
    "train_inputs,train_labels=load_input_data(train_data,labels)\n",
    "print('finish load_training_data')\n",
    "val_inputs,val_labels=load_input_data(val_data,labels)\n",
    "print('finish load_val_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_inputs[0].size()=torch.Size([801, 35])\n",
      "train_labels[0].size()=torch.Size([801, 1])\n",
      "average_length=1055_median_length=907_max_len=2801\n"
     ]
    }
   ],
   "source": [
    "print(f'{train_inputs[0].size()=}')\n",
    "print(f'{train_labels[0].size()=}')\n",
    "\n",
    "# 计算第一个维度的总长度\n",
    "total_length = sum(tensor.size(0) for tensor in train_inputs)\n",
    "# 计算平均长度\n",
    "average_length = total_length // len(train_inputs)\n",
    "\n",
    "\n",
    "# 提取每个张量的第一个维度长度\n",
    "lengths = [tensor.size(0) for tensor in train_inputs]\n",
    "\n",
    "# 对长度进行排序\n",
    "sorted_lengths = sorted(lengths)\n",
    "median_length=sorted_lengths[len(sorted_lengths)//2]\n",
    "max_len=sorted_lengths[-1]\n",
    "\n",
    "print(f'{average_length=}_{median_length=}_{max_len=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x:(batch_size,feature_dim)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        # Initialize positional encoding matrix\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to the input tensor\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class RegressionTransformer(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(RegressionTransformer, self).__init__()\n",
    "        self.args = args\n",
    "        # embed_dim = head_dim * num_heads?\n",
    "        self.embedding = nn.Linear(args['input_size'], args['d_model'])\n",
    "        self.output_fc = nn.Linear(args['input_size'], args['d_model'])\n",
    "        self.position_encoding = PositionalEncoding(args['d_model'], args['aligned_len'])  # Positional encoding layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=args['d_model'],\n",
    "            nhead=8,\n",
    "            dim_feedforward=4 * args['d_model'],\n",
    "            batch_first=True,\n",
    "            dropout=0.1,\n",
    "            device=args['device']\n",
    "        )\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=args['d_model'],\n",
    "            nhead=8,\n",
    "            dropout=0.1,\n",
    "            dim_feedforward=4 * args['d_model'],\n",
    "            batch_first=True,\n",
    "            device=args['device']\n",
    "        )\n",
    "        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=5)\n",
    "        self.decoder = torch.nn.TransformerDecoder(decoder_layer, num_layers=5)\n",
    "        self.fc = nn.Linear(args['d_model'], args['output_size'])\n",
    "        self.fc1 = nn.Linear(args['aligned_len'] * args['d_model'], args['d_model'])\n",
    "        self.fc2 = nn.Linear(args['d_model'], args['output_size'])\n",
    "\n",
    "        self.aligned_len = args['aligned_len']\n",
    "        self.input_atten_mask = self._generate_square_subsequent_mask(args['aligned_len'])\n",
    "        \n",
    "    def forward(self, x, y, input_mask, tgt_mask):\n",
    "    \n",
    "        input_atten_mask = self.input_atten_mask # shape(batchsize,seqlen,seqlen)\n",
    "        has_nan = torch.isnan(x).any()\n",
    "        # print(f'loc0{has_nan=}')\n",
    "        # x shape(batchsize,seqlen,input_size)\n",
    "        x = self.embedding(x) # x shape(batchsize,seqlen,d_model)\n",
    "        has_nan = torch.isnan(x).any()\n",
    "        # print(f'loc1{has_nan=}')\n",
    "        x = self.position_encoding(x)  # x shape(batchsize,seqlen,d_model)\n",
    "        has_nan = torch.isnan(x).any()\n",
    "        # print(f'loc2{has_nan=}')\n",
    "        x = self.encoder(src=x, mask=input_atten_mask, src_key_padding_mask=input_mask) # x shape(batchsize,seqlen,d_model)\n",
    "        has_nan = torch.isnan(x).any()\n",
    "        # print(f'loc3{has_nan=}')\n",
    "        # print(f'{y.shape=}_{x.shape=}')\n",
    "        extend_y=y.expand(-1, -1, self.args['d_model'])\n",
    "        x = self.decoder(tgt=extend_y, memory=x, tgt_mask=input_atten_mask) # x shape(batchsize,seqlen,d_model)\n",
    "        has_nan = torch.isnan(x).any()\n",
    "        # print(f'loc4{has_nan=}')\n",
    "        x = self.fc(x) # x shape(batchsize,seqlen,1)\n",
    "        has_nan = torch.isnan(x).any()\n",
    "        # print(f'loc5{has_nan=}')\n",
    "        return x\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, size):\n",
    "        mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        mask = mask.bool()\n",
    "        mask = mask.to(self.args['device'])\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1:\n",
      "tensor([[False,  True,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True,  True],\n",
      "        [False, False, False,  True,  True,  True],\n",
      "        [False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "def generate_square_subsequent_mask(size):\n",
    "        mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        mask = mask.bool()\n",
    "        return mask\n",
    "    \n",
    "    \n",
    "size = 6\n",
    "mask = generate_square_subsequent_mask(size)\n",
    "print(\"Test Case 1:\")\n",
    "print(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEWADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset definition\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, labels, maxlen, transform=None):\n",
    "        self.dataset=dataset\n",
    "        self.labels = labels  # Added feature_type argument\n",
    "        self.transform = transform\n",
    "        self.maxlen=maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature=self.dataset[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "\n",
    "         # Convert feature to torch.float32\n",
    "        feature = torch.tensor(feature, dtype=torch.float32)\n",
    "        # Convert label to torch.float32\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        pad_len = self.maxlen - feature.shape[0]\n",
    "        if pad_len > 0:\n",
    "            # print(f'before padding{feature.size()=}')\n",
    "            feature = torch.nn.functional.pad(feature, (0, 0, 0, pad_len), value=0)\n",
    "            # print(f'before padding{feature.size()=}')\n",
    "            # print(f'before padding{label.size()=}')\n",
    "            # label = torch.nn.functional.pad(label, (0,pad_len), value=0)  # Assuming -1 represents padding for labels\n",
    "            padding_length = self.maxlen - label.shape[0]\n",
    "            padding = torch.zeros(padding_length, 1)\n",
    "            label = torch.cat((label, padding), dim=0)\n",
    "\n",
    "            # print(f'after padding {label.size()=}')\n",
    "\n",
    "        if pad_len < 0:\n",
    "            \n",
    "            feature = feature[:self.maxlen]\n",
    "            label = label[:self.maxlen]\n",
    "        \n",
    "        \n",
    "        # Generate feature and label masks\n",
    "        feature_mask = torch.zeros(self.maxlen)\n",
    "        label_mask = torch.zeros(self.maxlen)\n",
    "        if pad_len > 0:\n",
    "            feature_mask[pad_len:] = 1  # Set mask to 1 for padded positions\n",
    "            label_mask[pad_len:] = 1  # Set mask to 1 for padded positions\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            feature = self.transform(feature)\n",
    "\n",
    "        return feature, label,feature_mask,label_mask\n",
    "    def get_all_labels(self):\n",
    "            return self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEWAdataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, num_workers=0):\n",
    "        super(SEWAdataLoader, self).__init__(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "      \n",
    "            \n",
    "    def __iter__(self):\n",
    "\n",
    "                for idx in range(0, len(self.dataset), self.batch_size):\n",
    "                    # get current mini-batch sample\n",
    "                    batch_data = []\n",
    "                    for i in range(idx, min(idx + self.batch_size, len(self.dataset))):\n",
    "                        batch_data.append(self.dataset[i])\n",
    "\n",
    "                    # Obtain the features and labels of each sample in the current mini-batch\n",
    "                    batch_inputs = [sample[0] for sample in batch_data]\n",
    "                    batch_labels = [sample[1] for sample in batch_data]\n",
    "                    batch_inputs_mask=[sample[2] for sample in batch_data]\n",
    "                    batch_labels_mask=[sample[3] for sample in batch_data]\n",
    "\n",
    "                    # print(f'{batch_inputs[0].size()=}_{batch_labels[0].size()=}_{batch_inputs_mask[0].size()=}_{batch_labels_mask[0].size()=}')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    tensor_inputs = torch.stack(batch_inputs, dim=0)\n",
    "                    tensor_labels = torch.stack(batch_labels, dim=0)\n",
    "                    tensor_inputs_mask = torch.stack(batch_inputs_mask, dim=0)\n",
    "                    tensor_labels_mask = torch.stack(batch_labels_mask, dim=0)\n",
    "                    # print(f'{tensor_inputs.shape=}')\n",
    "                    yield tensor_inputs, tensor_labels, tensor_inputs_mask, tensor_labels_mask\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs,device):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training the model\n",
    "        model = model.to(device)\n",
    "        model.train()\n",
    "        for batch_inputs, batch_labels,batch_inputs_mask,batch_labels_mask in train_loader:\n",
    "            # Passing input data x and labels y into the model\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            batch_inputs_mask = batch_inputs_mask.to(device)\n",
    "            batch_labels_mask = batch_labels_mask.to(device)\n",
    "            outputs = model(batch_inputs,batch_labels,batch_inputs_mask,batch_labels_mask)\n",
    "            \n",
    "            \n",
    "            flipped_labels_mask = (batch_labels_mask == 0)\n",
    "            \n",
    "            masked_outputs = outputs * flipped_labels_mask.float().unsqueeze(-1)\n",
    "            \n",
    "            \n",
    "            # masked_outputs = outputs * batch_labels_mask.unsqueeze(-1)\n",
    "            # print(f'{masked_outputs=}')\n",
    "            # 找到每个序列中的最小值和最大值\n",
    "            min_vals, _ = torch.min(masked_outputs, dim=1, keepdim=True)  # 在 seq_len 维度上找到最小值\n",
    "            max_vals, _ = torch.max(masked_outputs, dim=1, keepdim=True)  # 在 seq_len 维度上找到最大值\n",
    "\n",
    "            # 将每个元素减去最小值，然后除以最大值与最小值之差\n",
    "            normalized_outputs = (masked_outputs - min_vals) / (max_vals - min_vals)\n",
    "            \n",
    "            masked_labels = batch_labels * flipped_labels_mask.float().unsqueeze(-1)\n",
    "            # print(f'{normalized_outputs=}')\n",
    "            # print(f'{masked_labels=}')\n",
    "            loss = criterion(normalized_outputs, masked_labels)\n",
    "            print(f'{loss=}')\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "          # Printing the loss for the current iteration\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        \n",
    "    # Evaluating the model's performance\n",
    "    model.eval()\n",
    "    all_predicted = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_inputs, batch_labels in test_loader:\n",
    "       \n",
    "        # Forward propagation\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        total_loss += loss.item() * batch_inputs.size(0)\n",
    "        total_samples += batch_inputs.size(0)\n",
    "\n",
    "        # Calculating predicted values and true labels\n",
    "        all_predicted.extend(outputs.tolist())\n",
    "        all_labels.extend(batch_labels.tolist())\n",
    "\n",
    "    # Calculating MSE, MAE and R2 score\n",
    "    mse = mean_squared_error(all_labels, all_predicted)\n",
    "    mae = mean_absolute_error(all_labels, all_predicted)\n",
    "    r2 = r2_score(all_labels, all_predicted)\n",
    "\n",
    "    print(f'Mean Squared Error (MSE): {mse:.4f}, Mean Absolute Error (MAE): {mae:.4f}, R-squared (R2): {r2:.4f}')\n",
    "    return mse, mae, r2, all_predicted, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23487/3039105427.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feature = torch.tensor(feature, dtype=torch.float32)\n",
      "/tmp/ipykernel_23487/3039105427.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label, dtype=torch.float32)\n",
      "/home/ubuntu/anaconda3/envs/hr-viton/lib/python3.8/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([16, 907, 1])) that is different to the input size (torch.Size([16, 907, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.4751, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.1887, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.1643, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.1142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.1438, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [1/20], Loss: 0.0436\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.1383, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/hr-viton/lib/python3.8/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([1, 907, 1])) that is different to the input size (torch.Size([1, 907, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.1307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.1218, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0895, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.1163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0430, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [2/20], Loss: 0.0430\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.1068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0550, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [3/20], Loss: 0.0543\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0467, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [4/20], Loss: 0.0612\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0675, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [5/20], Loss: 0.0675\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0701, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [6/20], Loss: 0.0701\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0632, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [7/20], Loss: 0.0632\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [8/20], Loss: 0.0604\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0550, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [9/20], Loss: 0.0550\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [10/20], Loss: 0.0580\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [11/20], Loss: 0.0574\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [12/20], Loss: 0.0465\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0608, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [13/20], Loss: 0.0608\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [14/20], Loss: 0.0490\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0572, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [15/20], Loss: 0.0572\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [16/20], Loss: 0.0427\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [17/20], Loss: 0.0531\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [18/20], Loss: 0.0536\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0537, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [19/20], Loss: 0.0537\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n",
      "loss=tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch [20/20], Loss: 0.0441\n",
      "batch_inputs[0].size()=torch.Size([907, 35])_batch_labels[0].size()=torch.Size([907, 1])_batch_inputs_mask[0].size()=torch.Size([907])_batch_labels_mask[0].size()=torch.Size([907])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m testdataset\u001b[38;5;241m=\u001b[39mSEWADataset(dataset\u001b[38;5;241m=\u001b[39mval_inputs,labels\u001b[38;5;241m=\u001b[39mval_labels,maxlen\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maligned_len\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     20\u001b[0m test_loader\u001b[38;5;241m=\u001b[39mSEWAdataLoader(testdataset,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m mse, mae, r2,all_predicted,all_labels\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 50\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     47\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     48\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_inputs, batch_labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     51\u001b[0m    \n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Forward propagation\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(batch_inputs)\n\u001b[1;32m     54\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_labels)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "args = {\n",
    "    'input_size': 35,     # 每个帧的特征向量维度\n",
    "    'd_model': 64,        # Transformer隐藏单元数\n",
    "    'num_layers': 4,      # Encoder/Decoder层数\n",
    "    'output_size': 2,     # 输出的维度\n",
    "    'device': 'cuda',      # 训练设备\n",
    "    'aligned_len': 907,  # 对齐后的序列长度\n",
    "    'num_epochs': 20      # 训练的轮数\n",
    "}\n",
    "\n",
    "# 初始化模型\n",
    "model = RegressionTransformer(args)\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "traindataset=SEWADataset(dataset=train_inputs,labels=train_labels,maxlen=args['aligned_len'])\n",
    "train_loader=SEWAdataLoader(traindataset,batch_size=16)\n",
    "testdataset=SEWADataset(dataset=val_inputs,labels=val_labels,maxlen=args['aligned_len'])\n",
    "test_loader=SEWAdataLoader(testdataset,batch_size=16)\n",
    "mse, mae, r2,all_predicted,all_labels=train_model(model, train_loader, test_loader, criterion, optimizer, args['num_epochs'],args['device'])\n",
    "\n",
    "print(f'{mse=}_{mae=}_{r2=}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
